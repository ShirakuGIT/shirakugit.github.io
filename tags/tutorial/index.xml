<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial on Shiraku&#39;s Blog</title>
    <link>https://shirakugit.github.io/tags/tutorial/</link>
    <description>Recent content in Tutorial on Shiraku&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>Â© Shiraku</copyright>
    <lastBuildDate>Sun, 02 Jun 2024 17:32:01 +0530</lastBuildDate>
    <atom:link href="https://shirakugit.github.io/tags/tutorial/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Feature Scaling</title>
      <link>https://shirakugit.github.io/posts/feature-scaling/</link>
      <pubDate>Sun, 02 Jun 2024 17:32:01 +0530</pubDate>
      <guid>https://shirakugit.github.io/posts/feature-scaling/</guid>
      <description>Feature Scaling in Data Science and Machine Learning Feature scaling is a technique applied to columns of data. There are two main types of feature scaling:&#xA;Normalization Standardization Normalization Normalization scales all values to a range between 0 and 1. $$ X^{\prime}=\frac{X-X_{\min }}{X_{\max }-X_{\min }}$$&#xA;Standardization Standardization scales values to have a mean of 0 and a standard deviation of 1, typically resulting in values between -3 and +3, although values can exceed these limits in some cases.</description>
    </item>
  </channel>
</rss>
