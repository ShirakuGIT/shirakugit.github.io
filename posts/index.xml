<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Shiraku&#39;s Blog</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content in Posts on Shiraku&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>© Shiraku</copyright>
    <lastBuildDate>Sun, 16 Jun 2024 16:16:52 +0530</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Feature Scaling Part 2</title>
      <link>http://localhost:1313/posts/feature_scaling2/</link>
      <pubDate>Sun, 16 Jun 2024 16:16:52 +0530</pubDate>
      <guid>http://localhost:1313/posts/feature_scaling2/</guid>
      <description>Why Feature Scaling Should Be Done After Train-Test Split Feature scaling is a vital preprocessing step in machine learning that ensures all features are on a similar scale. This step is particularly crucial for algorithms that rely on distance metrics or gradient descent optimization. However, the timing of feature scaling—whether before or after splitting the data into training and test sets—can significantly impact the model&amp;rsquo;s performance and evaluation. This tutorial explains why feature scaling should be done after splitting the data and illustrates the concept with code examples and visualizations.</description>
    </item>
    <item>
      <title>Feature Scaling</title>
      <link>http://localhost:1313/posts/feature-scaling/</link>
      <pubDate>Sun, 02 Jun 2024 17:32:01 +0530</pubDate>
      <guid>http://localhost:1313/posts/feature-scaling/</guid>
      <description>Feature Scaling in Data Science and Machine Learning Feature scaling is a technique applied to columns of data. There are two main types of feature scaling:&#xA;Normalization Standardization Normalization Normalization scales all values to a range between 0 and 1. $$ X^{\prime}=\frac{X-X_{\min }}{X_{\max }-X_{\min }}$$&#xA;Standardization Standardization scales values to have a mean of 0 and a standard deviation of 1, typically resulting in values between -3 and +3, although values can exceed these limits in some cases.</description>
    </item>
    <item>
      <title>Whatsup</title>
      <link>http://localhost:1313/posts/whatsup/</link>
      <pubDate>Sun, 02 Jun 2024 11:39:14 +0530</pubDate>
      <guid>http://localhost:1313/posts/whatsup/</guid>
      <description>Hello!</description>
    </item>
  </channel>
</rss>
